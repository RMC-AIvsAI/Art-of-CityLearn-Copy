{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO, SAC\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from KBMproject import ATLA\n",
    "import KBMproject.utilities as utils\n",
    "\n",
    "from citylearn.data import DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'citylearn_challenge_2022_phase_2'\n",
    "SAVE_DIR = 'PPO agent 100 alts over 1000+200 2-3-21 results' + '/'\n",
    "TEST_NAME = 'SAC adversary BScaledSum mean diff 1-15-15'\n",
    "VERBOSITY = 0\n",
    "DEVICE = 'cuda'\n",
    "BINS = 20\n",
    "AGENT = 'Models/ATLA/PPO agent 100 alts over 1000+200 2-3-21.zip'\n",
    "ADVERSARY = 'Models/Adversary/SAC adversary BScaledSum mean diff 1-15-15.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define SB3 environments, note the the eval and training environments must be difference objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(\n",
    "    schema=DataSet.get_schema(DATASET_NAME),\n",
    "    action_bins=BINS,\n",
    "    seed=42,\n",
    "    T=None #this was supposed to make evaluations shorter, but does not work... never passed it in lol\n",
    ")\n",
    "agent_env = utils.make_discrete_env(**kwargs,)\n",
    "\n",
    "adv_env = utils.make_discrete_env(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each episode is 8759 timesteps\n"
     ]
    }
   ],
   "source": [
    "T = agent_env.time_steps - 1\n",
    "print(f'Each episode is {T} timesteps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define agent (could load/save pretrained agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== CURRENT SYSTEM INFO ==\n",
      "- OS: Windows-10-10.0.22631-SP0 10.0.22631\n",
      "- Python: 3.10.12\n",
      "- Stable-Baselines3: 1.8.0\n",
      "- PyTorch: 1.12.1\n",
      "- GPU Enabled: True\n",
      "- Numpy: 1.25.1\n",
      "- Gym: 0.21.0\n",
      "\n",
      "== SAVED MODEL SYSTEM INFO ==\n",
      "- OS: Windows-10-10.0.22631-SP0 10.0.22631\n",
      "- Python: 3.10.12\n",
      "- Stable-Baselines3: 1.8.0\n",
      "- PyTorch: 1.12.1\n",
      "- GPU Enabled: True\n",
      "- Numpy: 1.25.1\n",
      "- Gym: 0.21.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent = PPO.load(path=AGENT,\n",
    "                    env=agent_env,\n",
    "                    device=DEVICE,\n",
    "                    verbose=VERBOSITY,\n",
    "                    print_system_info=True,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose features which will be perturbed. The mask below leaves the temporal features unperturbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=np.arange(6,31) #only features 7-31 will be perturbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an adv action space in [-1,1] for ATLA.BScaledSumPrevProj, which scale a maximum perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kbrod\\AppData\\Roaming\\Python\\Python310\\site-packages\\gym\\spaces\\box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "normalized_a_space = gym.spaces.Box(low=-1*np.ones(mask.shape),\n",
    "                                    high=np.ones(mask.shape),\n",
    "                                    dtype='float32',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameterize the B function\n",
    "- The adversary adds a bounded perturbation to the current observation with B(s) as BScaledSum\n",
    "- The max mean difference represents the largest change between two samples for each feature minus the mean difference. This will be the maximum perturbation size for our adversary. Using the max difference represents the wors case scenario we expect to encounter based on our training data. Because this is derived from the difference between samples, we subtract the mean difference so on average the inter sample change will not exceed the max recorded value. This is our boundary for the adversary's perturbation.\n",
    "see bline obs analysis.ipynb in the PPO 500 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_mean_diff = np.array([0.24977164, 0.24977164, 0.34341758, 0.69515118, 0.04606484,\n",
    "                        0.04608573, 0.26690566, 0.26690266, 0.2669048 , 0.26690781,\n",
    "                        0.62865948, 0.62865314, 0.62865568, 0.62865948, 0.52596206,\n",
    "                        0.52596487, 0.52598294, 0.52596206, 0.75557218, 0.75558416,\n",
    "                        0.75558188, 0.75557218, 0.28202381, 0.61189055, 0.00253725,\n",
    "                        0.47459565, 0.0052361 , 0.89720221, 0.89720221, 0.89720221,\n",
    "                        0.89720221])\n",
    "\n",
    "mean_diff = np.array([0.12511418, 0.12511418, 0.18184461, 0.35953119, 0.10637713,\n",
    "                     0.10636668, 0.15978021, 0.15978171, 0.15978064, 0.15977914,\n",
    "                     0.36344801, 0.36345118, 0.36344991, 0.36344801, 0.3260062 ,\n",
    "                     0.3260048 , 0.32599576, 0.3260062 , 0.44802713, 0.44802114,\n",
    "                     0.44802228, 0.44802713, 0.16781362, 0.36620854, 0.00152669,\n",
    "                     0.31896562, 0.00326229, 0.52109586, 0.52109586, 0.52109586,\n",
    "                     0.52109586])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max perturbation reduced to mean diff devided by 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_params = dict(\n",
    "    #clip_bound=np.ones(agent_env.observation_space.shape)*0.33,\n",
    "    max_perturbation=np.ones(mask.shape)*mean_diff[mask]/2\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define adversary's environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(\n",
    "    #adv_reward=rwd, #use default negative agent reward\n",
    "    victim=agent,\n",
    "    B=ATLA.BScaledSum,\n",
    "    action_space=normalized_a_space, #[-1,1] for scaled B defined above\n",
    "    feature_mask=mask, \n",
    "    B_kwargs=B_params,\n",
    ")\n",
    "\n",
    "adv_env = ATLA.AdversaryATLAWrapper(env=adv_env, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_env(adv_env,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== CURRENT SYSTEM INFO ==\n",
      "- OS: Windows-10-10.0.22631-SP0 10.0.22631\n",
      "- Python: 3.10.12\n",
      "- Stable-Baselines3: 1.8.0\n",
      "- PyTorch: 1.12.1\n",
      "- GPU Enabled: True\n",
      "- Numpy: 1.25.1\n",
      "- Gym: 0.21.0\n",
      "\n",
      "== SAVED MODEL SYSTEM INFO ==\n",
      "- OS: Windows-10-10.0.19045-SP0 10.0.19045\n",
      "- Python: 3.10.12\n",
      "- Stable-Baselines3: 1.8.0\n",
      "- PyTorch: 1.12.1\n",
      "- GPU Enabled: True\n",
      "- Numpy: 1.23.5\n",
      "- Gym: 0.21.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adversary = SAC.load(path=ADVERSARY,\n",
    "                    env=adv_env,\n",
    "                    device=DEVICE,\n",
    "                    #tensorboard_log=LOG_DIR,\n",
    "                    verbose=VERBOSITY,\n",
    "                    print_system_info=True,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the adversary's perturbation function for the victim environment. We use a function which applies the corresponding B(s) to the adversary's prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbation = ATLA.sb3_perturbation(adversary,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap agent's environments for ATLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_env = ATLA.VictimATLAWrapper(agent_env,\n",
    "                                   perturbation,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_env(agent_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replace pre-training environment with ATLA environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.set_env(agent_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cost_function\n",
       "annual_peak_average                      1.042875\n",
       "carbon_emissions_total                   0.891042\n",
       "cost_total                               0.796751\n",
       "daily_one_minus_load_factor_average      1.033188\n",
       "daily_peak_average                       0.926451\n",
       "electricity_consumption_total            0.908205\n",
       "monthly_one_minus_load_factor_average    0.985678\n",
       "ramping_average                          1.124090\n",
       "zero_net_energy                          1.103965\n",
       "Name: District, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kpi, obs, a = utils.eval_agent(agent_env, agent)\n",
    "display(kpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO agent 100 alts over 1000+200 2-3-21 results/KPIs.csv updated\n"
     ]
    }
   ],
   "source": [
    "kpi_savename = SAVE_DIR+'KPIs.csv'\n",
    "try:\n",
    "    df_kpis = pd.read_csv(kpi_savename, \n",
    "                          index_col=0)\n",
    "    df_kpis[TEST_NAME] = kpi.values\n",
    "    df_kpis.to_csv(kpi_savename)\n",
    "    print(f'{kpi_savename} updated')\n",
    "except:\n",
    "    kpi.name = TEST_NAME\n",
    "    kpi.to_csv(kpi_savename)\n",
    "    print(f'{kpi_savename} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sa = pd.DataFrame(obs)\n",
    "df_sa.columns = agent_env.observation_names\n",
    "df_sa['actions'] = a\n",
    "df_sa.to_csv(SAVE_DIR + TEST_NAME + ' obs-a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CityLearnART",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
