{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial for MMD with the TorchDrift library: https://towardsai.net/p/machine-learning/drift-detection-using-torchdrift-for-tabular-and-time-series-data\n",
    "\n",
    "more documentation on TorchDrift MMD: https://torchdrift.org/notebooks/note_on_mmd.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RED = \"\\033[91m\"\n",
    "AUTO = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import torchdrift.detectors as detectors\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_path = os.path.join(os.getcwd(), '..','20 bin PPO 500 results/baseline_obs.csv')\n",
    "baseline_path = os.path.normpath(baseline_path) #resolve '..'\n",
    "df_baseline_obs = pd.read_csv(baseline_path, index_col=0, dtype='float32')\n",
    "df_baseline_obs.set_index(df_baseline_obs.index.astype(int), inplace=True) #line above makes the index a float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### On the (Statistical) Detection of Adversarial Examples\n",
    "\n",
    "**Two-sample hypothesis testing** — As stated before, the test we chose is appropriate to handle high dimensional inputs and small sample sizes. We compute the biased estimate of MMD using a **Gaussian kernel**, and then apply **10 000 bootstrapping iterations** to estimate the distributions. Based on this, we compute the **pvalue** and compare it to the threshold, in our experiments **0.05**. For samples of **legitimate data, the observed p-value should always be very high**, whereas for sample sets containing adversarial examples, we expect it to be low—since they are sampled from a different distribution and thus the hypothesis should be rejected. The test is more likely to detect a difference in two distributions when it considers samples of large size (i.e., the sample contains more inputs from the distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOTSTRAP = 10_000\n",
    "PVAL = 0.05\n",
    "kernel = detectors.mmd.GaussianKernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our dataset is a time series, we will use MMD on different time segments rather than shuffling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmd:0.073, p-value:0.0\n",
      "mmd:0.030, p-value:0.0\n",
      "mmd:0.001, p-value:1.0\n",
      "mmd:0.026, p-value:0.0\n",
      "mmd:0.063, p-value:0.0\n",
      "mmd:0.106, p-value:0.0\n",
      "mmd:0.133, p-value:0.0\n",
      "mmd:0.139, p-value:0.0\n",
      "mmd:0.131, p-value:0.0\n"
     ]
    }
   ],
   "source": [
    "results = [] #tuple containing the mmd and pval\n",
    "segments = 10\n",
    "samples = np.array_split(df_baseline_obs, segments)\n",
    "for i in range(len(samples)-1):\n",
    "    result = detectors.kernel_mmd(torch.from_numpy(samples[i].values).to('cuda'), \n",
    "                                  torch.from_numpy(samples[1+1].values).to('cuda'), #I wrote 1+1 instead of i+1 LMAO, good thing I'm redoing this in baseline MMDs and it didn't make it to the thesis\n",
    "                                  n_perm=BOOTSTRAP,\n",
    "                                  kernel=kernel)\n",
    "    print(f'mmd:{result[0]:.3f}, p-value:{result[1]}')\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the p-value is not a useful metric in this test for finding adversarial samples, as it only correctly identifies that two segments are from the same distribution. Let's try shuffled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a p-value threshold of 0.05\n",
      "mmd:0.003, p-value:0.05469999834895134, \u001b[0mdistributions are identical\u001b[0m\n",
      "mmd:0.003, p-value:0.032600000500679016, \u001b[91mdistributions are distinct\u001b[0m\n",
      "mmd:0.001, p-value:1.0, \u001b[0mdistributions are identical\u001b[0m\n",
      "mmd:0.003, p-value:0.15770000219345093, \u001b[0mdistributions are identical\u001b[0m\n",
      "mmd:0.003, p-value:0.040699999779462814, \u001b[91mdistributions are distinct\u001b[0m\n",
      "mmd:0.004, p-value:0.002099999925121665, \u001b[91mdistributions are distinct\u001b[0m\n",
      "mmd:0.004, p-value:0.007999999448657036, \u001b[91mdistributions are distinct\u001b[0m\n",
      "mmd:0.002, p-value:0.307699978351593, \u001b[0mdistributions are identical\u001b[0m\n",
      "mmd:0.003, p-value:0.01719999872148037, \u001b[91mdistributions are distinct\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = [] #tuple containing the mmd and pval\n",
    "segments = 10\n",
    "samples = np.array_split(df_baseline_obs.sample(frac=1), segments)\n",
    "print(f'Using a p-value threshold of {PVAL}')\n",
    "for i in range(len(samples)-1):\n",
    "    result = detectors.kernel_mmd(torch.from_numpy(samples[i].values).to('cuda'), \n",
    "                                  torch.from_numpy(samples[1+1].values).to('cuda'),\n",
    "                                  n_perm=BOOTSTRAP,\n",
    "                                  kernel=kernel)\n",
    "    if result[1] > PVAL:\n",
    "        dist = 'identical'\n",
    "        colour = AUTO\n",
    "    else:\n",
    "        dist = 'distinct'\n",
    "        colour = RED\n",
    "    print(f'mmd:{result[0]:.3f}, p-value:{result[1]}, {colour}distributions are {dist}{AUTO}')\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load unperturbed observations from untargeted adversarial attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv_obs = pd.read_csv(os.path.normpath(os.path.join(os.getcwd(), '..','20 bin PPO 500 results/adv_obs.csv')), #navigate to another folder in parent dir\n",
    "                        index_col=0,\n",
    "                        dtype='float32')\n",
    "df_adv_obs.set_index(df_adv_obs.index.astype(int), inplace=True) #all data is loaded as float32, but the index should be an int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load perturbed observations from untargeted adversarial attack (100% adversarial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv_perturbed_obs = pd.read_csv(os.path.normpath(os.path.join(os.getcwd(), '..','20 bin PPO 500 results/adv_perturbed_obs.csv')), #navigate to another folder in parent dir\n",
    "                        index_col=0,\n",
    "                        dtype='float32')\n",
    "df_adv_perturbed_obs.set_index(df_adv_perturbed_obs.index.astype(int), inplace=True) #all data is loaded as float32, but the index should be an int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll get the MMD between two full distrubtions during evaluation, the observations from the environment and the same observations once perturbed by ACG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmd:0.00014674663543701172, p-value:1.0\n"
     ]
    }
   ],
   "source": [
    "result = detectors.kernel_mmd(torch.from_numpy(df_adv_obs.values).to('cuda'), #clean obs from adv trace\n",
    "                                  torch.from_numpy(df_adv_perturbed_obs.values).to('cuda'), #perturbed obs from adv trace\n",
    "                                  n_perm=BOOTSTRAP,\n",
    "                                  kernel=kernel)\n",
    "print(f'mmd:{result[0]}, p-value:{result[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMD sees no difference between the perturbed and unperturbed distributions! The MMD is smaller between these two distributaions than between segments of the baseline ditribution would it be different if the min/max normalization is undone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmd:0.000, p-value:0.9019999504089355\n"
     ]
    }
   ],
   "source": [
    "result = detectors.kernel_mmd(torch.from_numpy(df_baseline_obs.values).to('cuda'), #clean obs from clean trace\n",
    "                                  torch.from_numpy(df_adv_perturbed_obs.values).to('cuda'),#perturbed obs from adv trace\n",
    "                                  n_perm=BOOTSTRAP,\n",
    "                                  kernel=kernel)\n",
    "print(f'mmd:{result[0]:.3f}, p-value:{result[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv_obs['action'] = pd.read_csv(os.path.normpath(os.path.join(os.getcwd(), '..','20 bin PPO 500 results/adv_obs_a.csv')), \n",
    "                                   dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv_perturbed_obs['action'] = pd.read_csv(os.path.normpath(os.path.join(os.getcwd(), '..','20 bin PPO 500 results/adv_perturbed_obs_a.csv')), \n",
    "                                   dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are grouping our samples (observations/states) by class (action), to see if the normal and adversarial samples are drawn from the same distributions for each distinct class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(results): #results is a tuple of (action (mmd,pval))\n",
    "    for result in results:\n",
    "        if result[1][1] > PVAL:\n",
    "            dist = 'identical'\n",
    "            colour = AUTO\n",
    "        else:\n",
    "            dist = 'distinct'\n",
    "            colour = RED\n",
    "        print(f'For action {result[0]}: mmd:{result[1][0]:.3f}, p-value:{result[1][1]}, {colour}distributions are {dist}{AUTO}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For action 0: mmd:0.042, p-value:0.02499999850988388, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 1: mmd:0.024, p-value:0.0, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 2: mmd:0.055, p-value:0.0, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 3: mmd:0.009, p-value:0.0, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 4: mmd:0.080, p-value:0.016099998727440834, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 5: mmd:0.021, p-value:0.1103999987244606, \u001b[0mdistributions are identical\u001b[0m\n",
      "For action 6: mmd:0.006, p-value:0.00969999935477972, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 7: mmd:0.006, p-value:9.999999747378752e-05, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 8: mmd:0.022, p-value:0.0, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 9: mmd:0.021, p-value:0.0, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 10: mmd:0.040, p-value:0.0017999999690800905, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 11: mmd:0.021, p-value:0.0, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 12: mmd:0.008, p-value:0.0, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 13: mmd:0.021, p-value:0.0, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 14: mmd:0.045, p-value:0.020499998703598976, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 15: mmd:0.016, p-value:0.0, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 16: mmd:0.016, p-value:0.00019999999494757503, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 17: mmd:0.025, p-value:0.0, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 18: mmd:nan, p-value:0.0, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 19: mmd:0.013, p-value:0.009499999694526196, \u001b[91mdistributions are distinct\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "#import torch\n",
    "\n",
    "def process_action(i):\n",
    "    return i, detectors.kernel_mmd(torch.from_numpy(df_adv_obs[df_adv_obs['action']==i].iloc[:,:-1].values).to('cuda'), #slice excludes actions column\n",
    "                                  torch.from_numpy(df_adv_perturbed_obs[df_adv_perturbed_obs['action']==i].iloc[:,:-1].values).to('cuda'),\n",
    "                                  n_perm=BOOTSTRAP,\n",
    "                                  kernel=kernel)\n",
    "\n",
    "#%%time\n",
    "results = Parallel(n_jobs=10, #set n_jobs so you don't run out of vram, 10 is faster than 12, probably because that's exactly half of the threads needed, so 12 just results in more threads tripping over eachother to use the gpu\n",
    "            prefer='threads' #threads are like 8 times faster than multiprocessing, less overhead and the cpu work is negligable\n",
    "            )(delayed(process_action)(i) for i in range(df_adv_obs['action'].max().astype(int)+1))\n",
    "\n",
    "show_results(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works where the other test failed because a sample which originally lead to action X is different thatn a sample which leads to action Y + a perturbation which leads it to actions X...OR this difference is an artifact of the time series data and we are comparing sample from differen time of day or saeaions and the difference is not due to perturbations. \n",
    "- confirm if the difference is due to perturbations or time series artifacts \n",
    "- if due to perturbations:\n",
    "     - how many samples do we need for detection (this could be a metirc for Ranwa's competition), we can use a binary search, stating with half our adversarial samples\n",
    "     - does different regularization evade detection\n",
    "     - does another attack evade detection\n",
    "     - this was detected using like a year's (?) worth of data, could this feasible detect an attack before it's too late?\n",
    "     - does this still work if we are using last year's smaples to detect an attack next year? this detection was demo with the before and after from perturbations. IRL you would only have the after **Will detection work when the detector is fitted before an episode so it detects adversarial samples during an episode** ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to see if the detection is because the we are comparing sample from different times, so we will now only look at unperturbed samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For action 0: mmd:0.042, p-value:0.021399999037384987, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 1: mmd:0.024, p-value:9.999999747378752e-05, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 2: mmd:0.056, p-value:0.0, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 3: mmd:0.009, p-value:0.0, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 4: mmd:0.080, p-value:0.016999999061226845, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 5: mmd:0.021, p-value:0.1127999946475029, \u001b[0mdistributions are identical\u001b[0m\n",
      "For action 6: mmd:0.007, p-value:0.006099999882280827, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 7: mmd:0.006, p-value:0.00029999998514540493, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 8: mmd:0.022, p-value:0.0, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 9: mmd:0.021, p-value:0.0, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 10: mmd:0.040, p-value:0.002099999925121665, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 11: mmd:0.021, p-value:0.0, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 12: mmd:0.008, p-value:0.0, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 13: mmd:0.021, p-value:0.0, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 14: mmd:0.044, p-value:0.02279999852180481, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 15: mmd:0.016, p-value:0.0, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 16: mmd:0.017, p-value:0.0004999999655410647, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 17: mmd:0.025, p-value:0.0, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 18: mmd:nan, p-value:0.0, \u001b[91mdistributions are distinct\u001b[0m\n",
      "For action 19: mmd:0.013, p-value:0.010799999348819256, \u001b[91mdistributions are distinct\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def process_action(i):\n",
    "    return i, detectors.kernel_mmd(torch.from_numpy(df_adv_obs[df_adv_obs['action']==i].iloc[:,:-1].values).to('cuda'), #slice excludes actions column\n",
    "                                  torch.from_numpy(df_adv_obs[:-1][df_adv_perturbed_obs['action']==i].iloc[:,:-1].values).to('cuda'), #there is no action for the final observation, so there is one few adversarial sample than sample\n",
    "                                  n_perm=BOOTSTRAP,\n",
    "                                  kernel=kernel)\n",
    "\n",
    "#%%time\n",
    "results = Parallel(n_jobs=10, #set n_jobs so you don't run out of vram, 10 is faster than 12, probably because that's exactly half of the threads needed, so 12 just results in more threads tripping over eachother to use the gpu\n",
    "            prefer='threads' #threads are like 8 times faster than multiprocessing, less overhead and the cpu work is negligable\n",
    "            )(delayed(process_action)(i) for i in range(df_adv_obs['action'].max().astype(int)+1))\n",
    "\n",
    "show_results(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we aren't detecting adversarial examples, just these observations are fundamentally different...\n",
    "\n",
    "**TODO** compare the difference in MMDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CityLearnART",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
