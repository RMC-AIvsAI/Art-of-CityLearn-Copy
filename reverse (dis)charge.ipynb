{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_NAME = '20 bin PPO 500 results\\default_PPO_citylearn_challenge_2022_phase_2_Building_6_20_bins_500.zip'\n",
    "DATASET_NAME = 'citylearn_challenge_2022_phase_2' #only action is electrical storage\n",
    "SAVE_DIR = r'20 bin PPO 500 results\\binary classifier uACG results' + '/'\n",
    "EPS = 0.03\n",
    "ATK_NAME = 'bifurcated_uACG_DLloss_03_mask_time_solar_and_consumption'\n",
    "CONSUMPTION_IDX = 26\n",
    "SOLAR_IDX = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "from citylearn.data import DataSet\n",
    "\n",
    "from art.attacks.evasion import AutoConjugateGradient as ACG\n",
    "#from KBMproject.mybb import BrendelBethgeAttack as BBA\n",
    "from art.estimators.classification import PyTorchClassifier as classifier\n",
    "from art.utils import to_categorical\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "import KBMproject.utilities as utils\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = DataSet.get_schema(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: #try to load CityLearn schema\n",
    "    schema = DataSet.get_schema(DATASET_NAME)\n",
    "except: #load saved schema otherwise\n",
    "    with open(DATASET_NAME, 'r') as file:\n",
    "        schema = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define RL agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== CURRENT SYSTEM INFO ==\n",
      "- OS: Windows-10-10.0.22631-SP0 10.0.22631\n",
      "- Python: 3.10.12\n",
      "- Stable-Baselines3: 1.8.0\n",
      "- PyTorch: 1.12.1\n",
      "- GPU Enabled: True\n",
      "- Numpy: 1.25.1\n",
      "- Gym: 0.21.0\n",
      "\n",
      "== SAVED MODEL SYSTEM INFO ==\n",
      "- OS: Windows-10-10.0.19045-SP0 10.0.19045\n",
      "- Python: 3.10.12\n",
      "- Stable-Baselines3: 1.8.0\n",
      "- PyTorch: 1.12.0\n",
      "- GPU Enabled: True\n",
      "- Numpy: 1.25.1\n",
      "- Gym: 0.21.0\n",
      "\n",
      "Model loaded from storage\n"
     ]
    }
   ],
   "source": [
    "agent = PPO.load(path=f\"{AGENT_NAME}\",\n",
    "                 print_system_info=True)\n",
    "print('Model loaded from storage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = agent.action_space[0].n\n",
    "env = utils.make_discrete_env(schema=schema,  \n",
    "                        action_bins=bins,\n",
    "                        seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = env.observation_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_masks = np.ones(agent.observation_space.shape)\n",
    "observation_masks[0:6] = 0 #mask time features\n",
    "observation_masks[SOLAR_IDX] = 0\n",
    "observation_masks[CONSUMPTION_IDX] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputCombinationWrapper(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(OutputCombinationWrapper, self).__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.base_model(x)\n",
    "        lower_half, higher_half = torch.split(logits, logits.size(1) // 2, dim=1)\n",
    "        \n",
    "        # get the max of the lower and higher halves\n",
    "        lower_max = torch.max(lower_half, dim=1)[0]\n",
    "        higher_max = torch.max(higher_half, dim=1)[0]\n",
    "        \n",
    "        # concatenate the max of the lower and higher halves into a single tensor\n",
    "        output = torch.cat((lower_max.unsqueeze(1), higher_max.unsqueeze(1)), dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_policy = OutputCombinationWrapper(utils.extract_actor(agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_classifier = classifier(\n",
    "        model=agent_policy,\n",
    "        loss=utils.CWLoss(), \n",
    "        nb_classes=2,\n",
    "        input_shape=agent.observation_space.shape,\n",
    "        device_type='gpu',\n",
    "        clip_values = (agent.observation_space.low.min(),agent.observation_space.high.max()) #min and max values of each feature, brendle bethge attack only supports floats values and not array\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = 50\n",
    "iter = int(1000/init)\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "kwargs = {\"loss_type\": None,  #attack is not targeted, but targets used in function below -> those are model predictions\n",
    "          \"eps\": EPS, \n",
    "          \"eps_step\": 2*EPS, \n",
    "          \"batch_size\": 1, \n",
    "          \"nb_random_init\": init, #init, #try 0 to match myPGD\n",
    "          \"max_iter\": iter, #iter, #try 100 to match myPGD\n",
    "          \"norm\": \"inf\", \n",
    "          \"verbose\": False}\n",
    "attack = ACG(estimator=agent_classifier, **kwargs,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_untargeted_attack(agent, env, atk, time_steps:int=None, mask:list=None):\n",
    "    \"\"\"Evaluates an SB3 agent subject to untargeted observation perturbations generated by an ART evasion attack\"\"\"\n",
    "    obs_list = []\n",
    "    adv_obs_list = []\n",
    "    a_list = []\n",
    "    adv_a_list = []\n",
    "    asr = 0\n",
    "    n_features = agent.observation_space.shape[0]\n",
    "\n",
    "    observations = env.reset()\n",
    "    if time_steps is None:\n",
    "        time_steps = env.time_steps - 1\n",
    "    if mask is None:\n",
    "        mask=np.ones(n_features) #1 for all features\n",
    "\n",
    "    pbar = tqdm(total=time_steps)\n",
    "    for step in tqdm(range(time_steps)):\n",
    "\n",
    "        obs_list.append(observations)\n",
    "        actions = agent.predict(observations, deterministic=True)\n",
    "        a_list.append(actions[0])\n",
    "        if(actions[0] < agent.action_space[0].n//2): #has this caused an issue compared to myPGD? or does it just replace a prediction/forward pass? n/c from removing it\n",
    "            target = to_categorical([0],2)\n",
    "        else:\n",
    "            target = to_categorical([1],2)\n",
    "\n",
    "        adv_obs = np.expand_dims(observations, axis=0) #ART atks expect a 2d array\n",
    "        adv_obs = atk.generate(adv_obs, \n",
    "                               y=target, \n",
    "                               mask=mask)\n",
    "        adv_obs = np.squeeze(adv_obs) #CityLearn envs expect a 1d array\n",
    "        \n",
    "        a_adv, _ = agent.predict(adv_obs, deterministic=True)\n",
    "        if a_adv[0]!=actions[0]: #check if an adversarial example was crafted\n",
    "            asr+=1\n",
    "            adv_obs_list.append(adv_obs)\n",
    "        else:\n",
    "            adv_obs_list.append(np.array([np.nan]*n_features)) #same shape as observations\n",
    "\n",
    "        adv_a_list.append(a_adv[0])\n",
    "        observations, _, _, _ = env.step(a_adv)\n",
    "\n",
    "        #update progress bar including asr\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix({'ASR': asr/(step + 1)}, refresh=True)\n",
    "        if env.done:\n",
    "            break\n",
    "    \n",
    "    pbar.close()\n",
    "    asr/=time_steps\n",
    "    return utils.format_kpis(env), np.array(obs_list), np.array(adv_obs_list), np.array(a_list), np.array(adv_a_list), asr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 8758/8759 [6:58:06<00:02,  2.86s/it] ASR=0.223]  \n",
      "100%|██████████| 8759/8759 [6:58:06<00:00,  2.86s/it, ASR=0.223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 23min 32s\n",
      "Wall time: 6h 58min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kpis, obs, adv_obs, actions, adv_actions, asr = eval_untargeted_attack(agent, \n",
    "                                                                        env, \n",
    "                                                                        attack,\n",
    "                                                                        time_steps=None,\n",
    "                                                                        mask=observation_masks,\n",
    "                                                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prev ASR was 0.343"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SAVE_DIR+f'{ATK_NAME} parameters.json', 'w') as f:\n",
    "    json.dump(kwargs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cost_function\n",
       "annual_peak_average                      1.260144\n",
       "carbon_emissions_total                   0.895974\n",
       "cost_total                               0.824148\n",
       "daily_one_minus_load_factor_average      0.983028\n",
       "daily_peak_average                       0.953976\n",
       "electricity_consumption_total            0.902861\n",
       "monthly_one_minus_load_factor_average    0.988683\n",
       "ramping_average                          1.224616\n",
       "zero_net_energy                          1.112879\n",
       "Name: District, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(kpis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi = kpis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 bin PPO 500 results\\binary classifier uACG results/KPIs.csv updated\n"
     ]
    }
   ],
   "source": [
    "kpi_savename = SAVE_DIR+'KPIs.csv'\n",
    "try:\n",
    "    df_kpis = pd.read_csv(kpi_savename, index_col=0)\n",
    "    df_kpis[ATK_NAME] = kpi.values\n",
    "    df_kpis.to_csv(kpi_savename)\n",
    "    print(f'{kpi_savename} updated')\n",
    "except:\n",
    "    kpi.name = ATK_NAME\n",
    "    kpi.to_csv(kpi_savename)\n",
    "    print(f'{kpi_savename} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obs = pd.DataFrame(obs)\n",
    "df_obs.columns = cols\n",
    "df_obs['a'] = actions\n",
    "df_obs.to_csv(SAVE_DIR+ATK_NAME+' a-obs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obs = pd.DataFrame(adv_obs)\n",
    "df_obs.columns = cols\n",
    "df_obs['a'] = adv_actions\n",
    "df_obs.to_csv(SAVE_DIR+ATK_NAME+' adv a-obs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 bin PPO 500 results\\binary classifier uACG results/ASRs.csv updated\n"
     ]
    }
   ],
   "source": [
    "asr_savename = SAVE_DIR+'ASRs.csv'\n",
    "try:\n",
    "    df_asrs = pd.read_csv(asr_savename)\n",
    "    df_asrs[ATK_NAME] = asr\n",
    "    df_asrs.to_csv(asr_savename)\n",
    "    print(f'{asr_savename} updated')\n",
    "except:\n",
    "    asr = pd.Series([asr])\n",
    "    asr.name = ATK_NAME\n",
    "    asr.to_csv(asr_savename)\n",
    "    print(f'{asr_savename} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CityLearnART",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
