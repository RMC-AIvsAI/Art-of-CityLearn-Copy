{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial for MMD with the TorchDrift library: https://towardsai.net/p/machine-learning/drift-detection-using-torchdrift-for-tabular-and-time-series-data\n",
    "\n",
    "more documentation on TorchDrift MMD: https://torchdrift.org/notebooks/note_on_mmd.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RED = \"\\033[91m\"\n",
    "AUTO = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torchdrift.detectors as detectors\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r'default SAC 500 norm space results\\baseline_obs-a.csv'\n",
    "SEGMENTS = 52 #weeks\n",
    "SAVE_DIR = 'default SAC 500 norm space results' + '/'\n",
    "SEGMENT_NAME = 'week'\n",
    "SAVE_NAME = f'{SEGMENT_NAME}ly baseline MMD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(DATA_PATH,\n",
    "                      index_col=0,\n",
    "                      usecols = lambda x: x != 'actions', #excludes a col\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### On the (Statistical) Detection of Adversarial Examples\n",
    "\n",
    "**Two-sample hypothesis testing** — As stated before, the test we chose is appropriate to handle high dimensional inputs and small sample sizes. We compute the biased estimate of MMD using a **Gaussian kernel**, and then apply **10 000 bootstrapping iterations** to estimate the distributions. Based on this, we compute the **pvalue** and compare it to the threshold, in our experiments **0.05**. For samples of **legitimate data, the observed p-value should always be very high**, whereas for sample sets containing adversarial examples, we expect it to be low—since they are sampled from a different distribution and thus the hypothesis should be rejected. The test is more likely to detect a difference in two distributions when it considers samples of large size (i.e., the sample contains more inputs from the distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOTSTRAP = 10_000\n",
    "PVAL = 0.05\n",
    "kernel = detectors.mmd.GaussianKernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(results): #results is a tuple of (action (mmd,pval))\n",
    "    for result in results:\n",
    "        if result[1][1] > PVAL:\n",
    "            dist = 'identical'\n",
    "            colour = AUTO\n",
    "        else:\n",
    "            dist = 'distinct'\n",
    "            colour = RED\n",
    "        print(f'For week {result[0]}: mmd:{result[1][0]:.5f}, p-value:{result[1][1]}, {colour}distributions are {dist}{AUTO}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.array_split(df_data.to_numpy(), SEGMENTS) #using sklearn time series split, which returns indeces, might let me load all the data as a cuda tensor, instead of transfering it sequentially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take MMD of time series splits, so the MMD of each segment is taken from the year to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_action(i, dist1, dist2):\n",
    "    return i, detectors.kernel_mmd(torch.from_numpy(dist1).to('cuda'), \n",
    "                                  torch.from_numpy(dist2).to('cuda'), #excludes i\n",
    "                                  n_perm=BOOTSTRAP,\n",
    "                                  kernel=kernel)\n",
    "\n",
    "results = Parallel(n_jobs=2, #set n_jobs so you don't run out of vram, \n",
    "            prefer='threads' #threads are like 8 times faster than multiprocessing, less overhead and the cpu work is negligable\n",
    "            )(delayed(process_action)(i, samples[i + 1], np.concatenate(samples[:i + 1])) for i in tqdm(range(SEGMENTS - 1))) #offset  of 1 avoids comparing the 0th segment to the slice of [:0], which is empty\n",
    "                #a slice of samples is a list, so we concatinate them into a simgle array\n",
    "show_results(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd = [result[1][0].item() for result in results]\n",
    "pval = [result[1][1].item() for result in results]\n",
    "segment = [result[0] for result in results]\n",
    "df_results = pd.DataFrame({'MMD':mmd, 'P_value':pval})\n",
    "df_results.index.name = SEGMENT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(SAVE_DIR + SAVE_NAME + '.csv', \n",
    "                  #index=0,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CityLearnART",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
