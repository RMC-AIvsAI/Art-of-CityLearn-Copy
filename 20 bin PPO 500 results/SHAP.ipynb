{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_NAME = 'default_PPO_citylearn_challenge_2022_phase_2_Building_6_20_bins_500'\n",
    "SAVE_DIR = 'attribution/'\n",
    "ATTR = 'SVS'\n",
    "SAMPLES = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from captum.attr import ShapleyValueSampling\n",
    "import torch\n",
    "\n",
    "from citylearn.data import DataSet\n",
    "\n",
    "import KBMproject.utilities as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from storage\n"
     ]
    }
   ],
   "source": [
    "agent = PPO.load(path=f\"{AGENT_NAME}\")\n",
    "print('Model loaded from storage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = utils.extract_actor(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVS = ShapleyValueSampling(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.estimators.classification import PyTorchClassifier as classifier\n",
    "from torch.nn import CrossEntropyLoss\n",
    "victim_policy = classifier(\n",
    "    model=actor,\n",
    "    loss=CrossEntropyLoss(), \n",
    "    nb_classes=agent.action_space[0].n,\n",
    "    input_shape=agent.observation_space.shape,\n",
    "    device_type='gpu',\n",
    "    clip_values = (agent.observation_space.low.min(),agent.observation_space.high.max()) #min and max values of each feature, brendle bethge attack only supports floats values and not array\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_bb_obs = pd.read_csv('bb results/clean obs.csv',\n",
    "                           index_col=0,\n",
    "                           dtype='float32')\n",
    "df_adv_bb_obs = pd.read_csv('bb results/bb obs.csv',\n",
    "                         index_col=0,\n",
    "                         dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_bb_a = np.argmax(victim_policy.predict(df_clean_bb_obs), axis=1)\n",
    "adv_bb_a = np.argmax(victim_policy.predict(df_adv_bb_obs), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_acg_obs = pd.read_csv('adv_obs.csv',\n",
    "                           index_col=0,\n",
    "                           dtype='float32')\n",
    "df_adv_acg_obs = pd.read_csv('adv_perturbed_obs.csv',\n",
    "                         index_col=0,\n",
    "                         dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_acg_a = np.argmax(victim_policy.predict(df_clean_acg_obs), axis=1)\n",
    "adv_acg_a = np.argmax(victim_policy.predict(df_adv_acg_obs), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline_obs = pd.read_csv('baseline_obs.csv',\n",
    "                         index_col=0,\n",
    "                         dtype='float32')\n",
    "baseline_a = np.loadtxt('baseline_obs_a.csv',\n",
    "                         delimiter=',',\n",
    "                         ).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebaseline_obs = np.loadtxt('rebaseline obs.csv',\n",
    "                         delimiter=',',\n",
    "                         ).astype('float32')\n",
    "rebaseline_a = np.loadtxt('rebaseline a.csv',\n",
    "                         delimiter=',',\n",
    "                         ).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_bb_shap = SVS.attribute(torch.from_numpy(\n",
    "                                            df_clean_bb_obs.to_numpy()\n",
    "                                            ).to('cuda'), #convert df to cuda tensor\n",
    "                             target=torch.from_numpy(clean_bb_a.flatten()).to('cuda'), #convert actions to 1d list\n",
    "                             n_samples=SAMPLES\n",
    "                             ).detach().cpu().numpy() #move results to cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_bb_shap = SVS.attribute(torch.from_numpy(df_adv_bb_obs.to_numpy()).to('cuda'),\n",
    "                             target=torch.from_numpy(adv_bb_a.flatten()).to('cuda'),\n",
    "                             n_samples=SAMPLES\n",
    "                             ).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_acg_shap = SVS.attribute(torch.from_numpy(df_clean_acg_obs.to_numpy()).to('cuda'),\n",
    "                             target=torch.from_numpy(clean_acg_a.flatten()).to('cuda'),\n",
    "                             n_samples=SAMPLES\n",
    "                             ).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_acg_shap = SVS.attribute(torch.from_numpy(df_adv_acg_obs.to_numpy()).to('cuda'),\n",
    "                             target=torch.from_numpy(adv_acg_a.flatten()).to('cuda'),\n",
    "                             n_samples=SAMPLES\n",
    "                             ).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_shap = SVS.attribute(torch.from_numpy(df_baseline_obs.to_numpy()).to('cuda'),\n",
    "                             target=torch.from_numpy(baseline_a.flatten()).to('cuda'),\n",
    "                             n_samples=SAMPLES\n",
    "                             ).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebaseline_shap = SVS.attribute(torch.from_numpy(rebaseline_obs).to('cuda'),\n",
    "                             target=torch.from_numpy(rebaseline_a).to('cuda'),\n",
    "                             n_samples=SAMPLES\n",
    "                             ).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = utils.make_discrete_env(schema=DataSet.get_schema(DATASET_NAME),  \n",
    "                        action_bins=agent.action_space[0].n,\n",
    "                        seed=42)\n",
    "cols = env.observation_names                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(SAVE_DIR + f'clean bb {ATTR} {SAMPLES}.csv', clean_bb_shap, delimiter=',')\n",
    "np.savetxt(SAVE_DIR + f'adv bb {ATTR} {SAMPLES}.csv', adv_bb_shap, delimiter=',')\n",
    "np.savetxt(SAVE_DIR + f'clean acg {ATTR} {SAMPLES}.csv', clean_acg_shap, delimiter=',')\n",
    "np.savetxt(SAVE_DIR + f'adv acg {ATTR} {SAMPLES}.csv', adv_acg_shap, delimiter=',')\n",
    "np.savetxt(SAVE_DIR + f'baseline {ATTR} {SAMPLES}.csv', baseline_shap, delimiter=',')\n",
    "np.savetxt(SAVE_DIR + f'rebaseline {ATTR} {SAMPLES}.csv', rebaseline_shap, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CityLearnART",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
