{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import SAC\n",
    "\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "from citylearn.wrappers import NormalizedObservationWrapper, StableBaselines3Wrapper\n",
    "from citylearn.data import DataSet\n",
    "\n",
    "from art.estimators.classification import PyTorchClassifier as classifier\n",
    "from art.attacks.evasion import AutoConjugateGradient as ACG\n",
    "\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from torch import from_numpy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from typing import List\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'citylearn_challenge_2022_phase_1' #only action is electrical storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = DataSet.get_schema(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_SB3_env(schema, bldg: list = ['Building_1'], single_agent: bool = True, seed:int =0):\n",
    "    \"\"\"Because ART's attacks are designed for supervised learning they one work with ANNs with a single label or head, using multiple buildings adds an action/head for each\"\"\"\n",
    "    env = CityLearnEnv(schema, \n",
    "        central_agent=single_agent, \n",
    "        buildings=bldg, \n",
    "        random_seed=seed)\n",
    "    env = NormalizedObservationWrapper(env)\n",
    "    env = StableBaselines3Wrapper(env)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_SB3_env(schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define vectorized training environment, seems that citylearn is not compatible: \"TypeError: 'StableBaselines3Wrapper' object is not callable\" is raised by \n",
    "\n",
    "num_cpu = cpu_count()\n",
    "\n",
    "subproc_vec_env = DummyVecEnv([make_discrete_env(schema=schema, action_bins=20, seed=i) for i in range(num_cpu)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define RL agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_kwargs = dict(net_arch=[256, 256])\n",
    "agent = SAC('MlpPolicy', \n",
    "            env,\n",
    "            device='cuda',\n",
    "            policy_kwargs=policy_kwargs,\n",
    "            tensorboard_log='logs/Phase1/SAC/',\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContinuousCritic(\n",
       "  (features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (qf0): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (qf1): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actor(\n",
       "  (features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (latent_pi): Sequential(\n",
       "    (0): Linear(in_features=31, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (mu): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (log_std): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.actor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train victim agent (Python: Launch Tensorboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 20\n",
    "T = env.time_steps - 1\n",
    "agent_name = f'default_SAC_{dataset_name}_{episodes}'\n",
    "\n",
    "try:\n",
    "    agent = agent.load(path=f\"Models/Victim/{agent_name}\", env=env)\n",
    "except:\n",
    "    print(\"No saved agent found by that name\")\n",
    "    agent.learn(total_timesteps=int(T*episodes), tb_log_name=agent_name, progress_bar=True)\n",
    "    agent.save(f\"Models/Victim/{agent_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_kpis(env):\n",
    "    \"\"\"displays the KPIs from the evnironment's most recent timestep.\n",
    "    This function can be called after an agent runs in a test env to evaluate performance\"\"\"\n",
    "\n",
    "    kpis = env.evaluate().pivot(index='cost_function', columns='name', values='value')\n",
    "    kpis = kpis.dropna(how='all')\n",
    "    display(kpis['District']) #the district values are all we need with a single building (cells are either repeated or NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_agent(env, agent):\n",
    "    \"\"\"displays the KPIs for each building and district\n",
    "    ref quickstart\"\"\"\n",
    "    observations = env.reset()\n",
    "\n",
    "    while not env.done:\n",
    "        actions, _ = agent.predict(observations, deterministic=True)\n",
    "        observations, _, _, _ = env.step(actions)\n",
    "\n",
    "    display_kpis(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unperturbed agent performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cost_function\n",
       "annual_peak_average                      1.001616\n",
       "carbon_emissions_total                   0.994202\n",
       "cost_total                               0.969934\n",
       "daily_one_minus_load_factor_average      0.993918\n",
       "daily_peak_average                       1.008839\n",
       "discomfort_delta_average                 0.000000\n",
       "discomfort_delta_maximum                 0.000000\n",
       "discomfort_delta_minimum                 0.000000\n",
       "electricity_consumption_total            0.997156\n",
       "monthly_one_minus_load_factor_average    0.997524\n",
       "ramping_average                          1.232901\n",
       "zero_net_energy                          1.046888\n",
       "Name: District, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_agent(env,agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_rand_attack(agent, env, eps=0.3):\n",
    "    \"\"\"displays the KPIs for each building and district withc random noise in the observations\n",
    "    ref quickstart\"\"\"\n",
    "    observations = env.reset()\n",
    "    asr = 0\n",
    "\n",
    "    while not env.done:\n",
    "        noisey_obs = observations + np.random.rand(*observations.shape)*eps\n",
    "        a_adv, _ = agent.predict(noisey_obs, deterministic=True)\n",
    "        actions, _ = agent.predict(observations, deterministic=True)\n",
    "        if a_adv!=actions: #check if the perturbation changed the agent's action\n",
    "            asr+=1\n",
    "        observations, _, _, _ = env.step(a_adv)\n",
    "\n",
    "    asr/=env.time_steps\n",
    "    print(f'The Adversarial success rate is: {asr}')\n",
    "    display_kpis(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model performance while observations are perturbed by random noise [0,1). Note that all the observation values are normalized to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Adversarial success rate is: 0.9998858447488584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cost_function\n",
       "annual_peak_average                      1.188810\n",
       "carbon_emissions_total                   1.039336\n",
       "cost_total                               1.019354\n",
       "daily_one_minus_load_factor_average      0.999066\n",
       "daily_peak_average                       1.089598\n",
       "discomfort_delta_average                 0.000000\n",
       "discomfort_delta_maximum                 0.000000\n",
       "discomfort_delta_minimum                 0.000000\n",
       "electricity_consumption_total            1.042609\n",
       "monthly_one_minus_load_factor_average    1.005882\n",
       "ramping_average                          1.429770\n",
       "zero_net_energy                          1.062409\n",
       "Name: District, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_rand_attack(agent, env, eps=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our gradient based attack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_SAC_policy(agent):\n",
    "    \"\"\"Extracts the policy network from and SB3 actor critic algorithm as a pytorch seuqential network\"\"\"\n",
    "    from copy import deepcopy\n",
    "    policy_net = deepcopy(agent.actor.latent_pi) #copies shared net rather than referencing/changing the agent\n",
    "    policy_net.add_module('output', agent.actor.mu)\n",
    "    return policy_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the victim policy need to be processed as ART regressor->BlackBoxClassifier->attack?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_attack(agent, ART_atk, loss_fn=CrossEntropyLoss(), nb_classes:int=10, **kwargs):\n",
    "    \"\"\"returns an ART attack function based on the input gym enviornment, SB3 Agent and ART attack class\"\"\"\n",
    "    \n",
    "    agent_policy = extract_SAC_policy(agent)\n",
    "\n",
    "    #Treat the regressor as a classifier\n",
    "    victim_policy = classifier(\n",
    "        model=agent_policy,\n",
    "        loss=loss_fn,\n",
    "        nb_classes=nb_classes,\n",
    "        input_shape=agent.observation_space.shape,\n",
    "        )\n",
    "        \n",
    "    return ART_atk(victim_policy, verbose=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The black box classifier does not support cross entropy or DLR, and selecting neith results in an input type error. Maybe a differnet attack will work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = define_attack(agent, ACG, **ACG_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_untargeted_attack(agent, atk, time_steps:int=None, mask:list=None):\n",
    "    \"\"\"Evaluates an SB3 agent subject to untargeted observation perturbations generated by an ART evasion attack\"\"\"\n",
    "    observations = env.reset()\n",
    "    asr = 0\n",
    "    failed_adv_exs = 0\n",
    "    if time_steps is None:\n",
    "        time_steps = env.time_steps - 1\n",
    "    if mask is None:\n",
    "        mask=np.ones(agent.observation_space.shape[0]) #1 for all features\n",
    "\n",
    "    for i in tqdm(range(time_steps)):\n",
    "\n",
    "        adv_obs = np.expand_dims(observations, axis=0) #ART atks expect a 2d array\n",
    "        #would using the true label/action imporve the asr? it would hurt adversarial training: https://arxiv.org/abs/1611.01236\n",
    "        adv_obs = atk.generate(adv_obs, mask=mask) #add a mask (0) for features like time where changes would be obvious\n",
    "        adv_obs = np.squeeze(adv_obs) #CityLearn envs expect a 1d array\n",
    "        \n",
    "        a_adv, _ = agent.predict(adv_obs, deterministic=True)\n",
    "        actions, _ = agent.predict(observations, deterministic=True)\n",
    "        if a_adv!=actions: #check if the perturbation changed the agent's action\n",
    "            asr+=1\n",
    "        elif np.array_equal(adv_obs, observations): #when the victim's action is unchanged, check if an adv observation was crafted\n",
    "            failed_adv_exs+=1\n",
    "        observations, _, _, _ = env.step(a_adv)\n",
    "\n",
    "        if env.done:\n",
    "            break\n",
    "\n",
    "    asr/=time_steps\n",
    "    print(f'The Adversarial success rate is: {asr}')\n",
    "    print(f'{failed_adv_exs} adversarial examples were produced but failed to change the victim\\'s action')\n",
    "    display_kpis(env)\n",
    "    return asr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before attacking the victim, we must understand what we are perturbing. So we need to see which observations/features are active in the environment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that all these observations are variable (changes to constant values would indicate perturbations), however perturbations to the date and time would be obvious to an analyst. We will mask these features in our attack to they will not be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This seems to be missing some observations, like building set-points, these might be added later\n",
    "#env.observation_names was added in later version, but thatse break display kpis\n",
    "#observation_mask = dict(zip(observation_names, np.ones(len(observation_names))))\n",
    "#observation_mask['month'] = 0\n",
    "#observation_mask['day_type'] = 0\n",
    "#observation_mask['hour'] = 0\n",
    "#mask=np.array(list(observation_mask.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_time=np.ones(agent.observation_space.shape[0]) #permits attack on all features/observations\n",
    "mask_time[0:3]=0 #masks the first three observations/features which correspond to the date/time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ZOO and Hop Skip Jump raise the same error as ACG, but during generation rather than attack definition. converting the sample to a tensor does remove the error, I suspect the issues is the input type for the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected floating point type for target with class probabilities, got Int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m asr \u001b[39m=\u001b[39m eval_untargeted_attack(agent, attack, time_steps\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, mask\u001b[39m=\u001b[39;49mmask_time)\n",
      "Cell \u001b[1;32mIn[41], line 15\u001b[0m, in \u001b[0;36meval_untargeted_attack\u001b[1;34m(agent, atk, time_steps, mask)\u001b[0m\n\u001b[0;32m     13\u001b[0m adv_obs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(observations, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m#ART atks expect a 2d array\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m#would using the true label/action imporve the asr? it would hurt adversarial training: https://arxiv.org/abs/1611.01236\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m adv_obs \u001b[39m=\u001b[39m atk\u001b[39m.\u001b[39;49mgenerate(adv_obs, mask\u001b[39m=\u001b[39;49mmask) \u001b[39m#add a mask (0) for features like time where changes would be obvious\u001b[39;00m\n\u001b[0;32m     16\u001b[0m adv_obs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqueeze(adv_obs) \u001b[39m#CityLearn envs expect a 1d array\u001b[39;00m\n\u001b[0;32m     18\u001b[0m a_adv, _ \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39mpredict(adv_obs, deterministic\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Broda-Milian\\anaconda3\\envs\\CityLearnART\\lib\\site-packages\\art\\attacks\\evasion\\auto_conjugate_gradient.py:484\u001b[0m, in \u001b[0;36mAutoConjugateGradient.generate\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    481\u001b[0m tol \u001b[39m=\u001b[39m \u001b[39m10e-8\u001b[39m\n\u001b[0;32m    483\u001b[0m \u001b[39m# Get gradient wrt loss; invert it if attack is targeted\u001b[39;00m\n\u001b[1;32m--> 484\u001b[0m grad \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator\u001b[39m.\u001b[39;49mloss_gradient(x_k, y_batch) \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargeted))\n\u001b[0;32m    485\u001b[0m \u001b[39mif\u001b[39;00m k_iter \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    486\u001b[0m     gradk_1 \u001b[39m=\u001b[39m grad\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\Broda-Milian\\anaconda3\\envs\\CityLearnART\\lib\\site-packages\\art\\estimators\\classification\\pytorch.py:836\u001b[0m, in \u001b[0;36mPyTorchClassifier.loss_gradient\u001b[1;34m(self, x, y, training_mode, **kwargs)\u001b[0m\n\u001b[0;32m    834\u001b[0m \u001b[39m# Compute the gradient and return\u001b[39;00m\n\u001b[0;32m    835\u001b[0m model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model(inputs_t)\n\u001b[1;32m--> 836\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_loss(model_outputs[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], labels_t)\n\u001b[0;32m    838\u001b[0m \u001b[39m# Clean gradients\u001b[39;00m\n\u001b[0;32m    839\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\Broda-Milian\\anaconda3\\envs\\CityLearnART\\lib\\site-packages\\art\\attacks\\evasion\\auto_conjugate_gradient.py:257\u001b[0m, in \u001b[0;36mAutoConjugateGradient.__init__.<locals>.CrossEntropyLossTorch.__call__\u001b[1;34m(self, y_true, y_pred, *args, **kwargs)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, y_true: torch\u001b[39m.\u001b[39mTensor, y_pred: torch\u001b[39m.\u001b[39mTensor, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m    256\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreduction \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 257\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mce_loss(y_true, y_pred)\u001b[39m.\u001b[39mmean()\n\u001b[0;32m    258\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreduction \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msum\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    259\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mce_loss(y_true, y_pred)\u001b[39m.\u001b[39msum()\n",
      "File \u001b[1;32mc:\\Users\\Broda-Milian\\anaconda3\\envs\\CityLearnART\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Broda-Milian\\anaconda3\\envs\\CityLearnART\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1164\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1164\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   1165\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   1166\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[1;32mc:\\Users\\Broda-Milian\\anaconda3\\envs\\CityLearnART\\lib\\site-packages\\torch\\nn\\functional.py:3014\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3012\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3013\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3014\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected floating point type for target with class probabilities, got Int"
     ]
    }
   ],
   "source": [
    "asr = eval_untargeted_attack(agent, attack, time_steps=20, mask=mask_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate agent with variable epsilon:\n",
    "- Start at min value and increase in loop\n",
    "- try multiple values in parallel\n",
    "- return stat on the eps used, box plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CityLearnART",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
