{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_NAME = 'Models\\Victim\\SAC_citylearn_challenge_2022_phase_2_Building_6_default_rwd_MARLISA_hyperparams_500.zip'\n",
    "DATASET_NAME = 'citylearn_challenge_2022_phase_2' #only action is electrical storage\n",
    "SAVE_DIR = 'default SAC 500 norm space results' + '/'\n",
    "ATK_NAME = 'untargeted_binary_myPGD_03_mask_time_REscale_solar_and_consumption_eps_clipped_adv_obs'\n",
    "CONSUMPTION_SPREAD = 0.016\n",
    "SOLAR_SPREAD = 0.004 #0.04 prev typo\n",
    "MIN_OBS = 0\n",
    "MAX_OBS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from stable_baselines3 import SAC\n",
    "\n",
    "from citylearn.data import DataSet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import KBMproject.utilities as utils\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = DataSet.get_schema(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = SAC.load(path=f\"{AGENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "policy_net = deepcopy(agent.actor.latent_pi) #copies shared net rather than referencing/changing the agent\n",
    "policy_net.add_module('4', agent.actor.mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = utils.make_continuous_env(schema=schema,  \n",
    "                        seed=42)\n",
    "cols = env.observation_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broken_pgd_linf(model, X, y, loss_fn, epsilon:float=0.05, step:float=0.01, num_iter:int=100, \n",
    "             num_restarts:int=5, num_decay:int=0, decay_rate=1):\n",
    "    \"\"\" Construct FGSM adversarial examples on the examples X with random restarts\"\"\"\n",
    "    max_loss = torch.zeros([num_restarts, y.shape[0]]).to(y.device)\n",
    "    max_delta = torch.zeros_like(X)\n",
    "\n",
    "    assert 0 < decay_rate <= 1, 'decay rate must be between 0 and 1'\n",
    "\n",
    "    if num_decay > 0: \n",
    "        decay_iters = num_iter//num_decay\n",
    "    else: #no decay\n",
    "        decay_iters = num_iter\n",
    "\n",
    "    # Create a tensor to hold delta for all restarts at once\n",
    "    delta = torch.rand(num_restarts, *X.shape, device=X.device, requires_grad=True)\n",
    "    # Scale the random values to the range [-epsilon, epsilon]\n",
    "    delta.data = delta.data * 2 * epsilon - epsilon\n",
    "\n",
    "    for iter in range(num_iter):\n",
    "        loss = loss_fn(reduction='none')(model(X + delta), y.unsqueeze(0).repeat(num_restarts, 1))\n",
    "        loss.backward(torch.ones_like(loss))\n",
    "\n",
    "        # Perform the update on delta (via the data attribute to skip the gradient tracking)\n",
    "        delta.data = (delta + step*delta.grad.detach().sign()).clamp(-epsilon, epsilon)\n",
    "        delta.grad.zero_()\n",
    "        \n",
    "        #find the best delta for all restarts\n",
    "        is_max = loss.unsqueeze(-1).unsqueeze(-1) >= max_loss.unsqueeze(-1).unsqueeze(-1)\n",
    "        max_delta = torch.where(is_max, delta.detach(), max_delta)\n",
    "        max_loss = torch.where(is_max.squeeze(-1).unsqueeze(-1), loss, max_loss)\n",
    "\n",
    "        if(iter%decay_iters == 0):\n",
    "            step *= decay_rate\n",
    "        \n",
    "    return max_delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pgd_linf(model, X, y=None, loss_fn=None, epsilon=0.05, step:float=0.01, num_iter:int=100, \n",
    "                num_decay:int=0, decay_rate=1):\n",
    "    \"\"\" Construct FGSM adversarial examples on the examples X with random restarts\n",
    "    ref: https://adversarial-ml-tutorial.org/adversarial_examples/\n",
    "    made for X as a single sample\"\"\"\n",
    "\n",
    "    assert 0 < decay_rate <= 1, 'decay rate must be between 0 and 1'\n",
    "    assert loss_fn is not None, 'Loss function must be provided'\n",
    "    model.eval()\n",
    "    if y is None:\n",
    "        y = model(X)\n",
    "        n_out = y.shape[0]\n",
    "        if n_out > 1: #multiple outputs, assumes X is 1d\n",
    "            _, y = torch.max(y, -1) #argmax, max returns (values, indeces)\n",
    "            y = F.one_hot(y,num_classes=n_out)\n",
    "\n",
    "    if num_decay > 0: \n",
    "        decay_iters = num_iter//num_decay\n",
    "    else: #no decay\n",
    "        decay_iters = num_iter\n",
    "\n",
    "    delta = torch.zeros_like(X, requires_grad=True)\n",
    "    for iter in range(num_iter):\n",
    "\n",
    "        loss = loss_fn(reduction='none')(model(X + delta), y)\n",
    "        loss.backward(torch.ones_like(loss))\n",
    "\n",
    "        # Perform the update on delta (via the data attribute to skip the gradient tracking)\n",
    "        delta.data = (delta + step*delta.grad.detach().sign()).clamp(-epsilon, epsilon)\n",
    "        delta.grad.zero_()\n",
    "        \n",
    "        if(iter%decay_iters == 0):\n",
    "            step *= decay_rate\n",
    "        \n",
    "    return delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressorLinearWrapper(nn.Module):\n",
    "    \"\"\"wraps a regressor\n",
    "    and replaces the single output with 2 logits, one is maximized at 0 \n",
    "    the other at 1 (by default)\n",
    "    y= m*x + b\"\"\"\n",
    "    def __init__(self, base_model, m1=1.0, b1=0.0, m2=-1.0, b2=0.0):\n",
    "        super(RegressorLinearWrapper, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.m1 = m1\n",
    "        self.m2 = m2\n",
    "        self.b1 = b1\n",
    "        self.b2 = b2\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.base_model(input)\n",
    "        \n",
    "        logits = torch.cat((self.m1*x + self.b1, self.m2*x + self.b2)).float()\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLLoss(nn.Module):\n",
    "    \"\"\"Carlini and Wagner or Difference Logits loss FOR UNTARGETED ATTACKS\n",
    "    where the loss is difference between the target/clean\n",
    "    logit and any other\"\"\"\n",
    "    def __init__(self, reduction=None):\n",
    "        super(DLLoss, self).__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, target_one_hot): #myPGD doesn't provide a 1 hot target...\n",
    "        target_logits = torch.sum(target_one_hot * logits)\n",
    "        max_non_target_logits = torch.max((1 - target_one_hot) * logits)\n",
    "        loss = max_non_target_logits - target_logits\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:  #reduction is None\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust epsilon for different features, the slice from 0 to 6 are temporal features and setting $\\epsilon$ to 0 means that these features will not be perturbed (using torch.clamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'solar_generation'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_names[0][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_idx = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'net_electricity_consumption'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_names[0][26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption_idx = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_list = np.ones(agent.observation_space.shape[0])*0.03\n",
    "eps_list[:6] = 0.0 #masked\n",
    "#these idx are improperly normalized, so eps bust be adjusted accordingly\n",
    "eps_list[solar_idx] *= SOLAR_SPREAD\n",
    "eps_list[consumption_idx] *= CONSUMPTION_SPREAD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(\n",
    "    model=RegressorLinearWrapper(policy_net),\n",
    "    epsilon=torch.tensor(eps_list, device=agent.device, dtype=torch.float32),\n",
    "    step=0.01,\n",
    "    num_iter=100,\n",
    "    num_decay=4,\n",
    "    decay_rate=0.5,\n",
    "    loss_fn=DLLoss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs['model'].base_model[-1].out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 8758/8759 [23:04<00:00,  6.32it/s] MAE=0.109]\n",
      "100%|██████████| 8759/8759 [23:04<00:00,  6.32it/s, MAE=0.109]\n"
     ]
    }
   ],
   "source": [
    "time_steps = None\n",
    "\n",
    "obs_list = []\n",
    "adv_obs_list = []\n",
    "a_list = []\n",
    "adv_a_list = []\n",
    "mae = 0\n",
    "n_features = agent.observation_space.shape[0]\n",
    "\n",
    "observations = env.reset()\n",
    "if time_steps is None:\n",
    "    time_steps = env.time_steps - 1\n",
    "\n",
    "pbar = tqdm(total=time_steps)\n",
    "for step in tqdm(range(time_steps)):\n",
    "\n",
    "    obs_list.append(observations)\n",
    "    actions = agent.predict(observations, deterministic=True)\n",
    "    a_list.append(actions[0])\n",
    "\n",
    "    delta = my_pgd_linf(X=torch.from_numpy(observations).to(agent.device),\n",
    "#try toggling the one hot target y based on odd/even steps to imitat the optimal adversarial policy\n",
    "                                         **kwargs).cpu().detach().numpy()\n",
    "\n",
    "    adv_obs = np.clip(observations + delta, MIN_OBS, MAX_OBS) #keep adv obs in obs space\n",
    "    adv_obs_list.append(adv_obs)\n",
    "    \n",
    "    a_adv, _ = agent.predict(adv_obs, deterministic=True)\n",
    "    a_dist = abs(a_adv[0] - actions[0])[0]\n",
    "    mae += a_dist\n",
    "\n",
    "    adv_a_list.append(a_adv[0])\n",
    "    observations, _, _, _ = env.step(a_adv)\n",
    "\n",
    "    #update progress bar including MAE\n",
    "    pbar.update(1)\n",
    "    pbar.set_postfix({'MAE': mae/(step + 1)}, refresh=True)\n",
    "    if env.done:\n",
    "        break\n",
    "\n",
    "pbar.close()\n",
    "mae/=time_steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cost_function\n",
       "annual_peak_average                      1.046289\n",
       "carbon_emissions_total                   0.958512\n",
       "cost_total                               0.921895\n",
       "daily_one_minus_load_factor_average      0.989155\n",
       "daily_peak_average                       1.030163\n",
       "electricity_consumption_total            0.965838\n",
       "monthly_one_minus_load_factor_average    0.996660\n",
       "ramping_average                          1.361771\n",
       "zero_net_energy                          1.084689\n",
       "Name: District, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kpi = utils.format_kpis(env)\n",
    "display(kpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KPIs.csv updated\n"
     ]
    }
   ],
   "source": [
    "kpi_savename = SAVE_DIR+'KPIs.csv'\n",
    "try:\n",
    "    df_kpis = pd.read_csv(kpi_savename,\n",
    "                          index_col=0)\n",
    "    df_kpis[ATK_NAME] = kpi.values\n",
    "    df_kpis.to_csv(kpi_savename)\n",
    "    print('KPIs.csv updated')\n",
    "except:\n",
    "    kpi.name = ATK_NAME\n",
    "    kpi.to_csv(kpi_savename)\n",
    "    print('KPIs.csv created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obs = pd.DataFrame(obs_list)\n",
    "df_obs.columns = cols\n",
    "df_obs['a'] = np.array(a_list).flatten().tolist()\n",
    "df_obs.to_csv(SAVE_DIR+ATK_NAME+'_obs-a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obs = pd.DataFrame(adv_obs_list)\n",
    "df_obs.columns = cols\n",
    "df_obs['a'] = np.array(adv_a_list).flatten().tolist()\n",
    "df_obs.to_csv(SAVE_DIR+ATK_NAME+'_adv_obs-a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default SAC 500 norm space results/MAEs.csv updated\n"
     ]
    }
   ],
   "source": [
    "asr_savename = SAVE_DIR+'MAEs.csv'\n",
    "try:\n",
    "    df_asrs = pd.read_csv(asr_savename,\n",
    "                          index_col=0)\n",
    "    df_asrs[ATK_NAME] = mae\n",
    "    df_asrs.to_csv(asr_savename)\n",
    "    print(f'{asr_savename} updated')\n",
    "except:\n",
    "    asr = pd.Series([mae])\n",
    "    asr.name = ATK_NAME\n",
    "    asr.to_csv(asr_savename)\n",
    "    print(f'{asr_savename} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'epsilon', 'step', 'num_iter', 'num_decay', 'decay_rate', 'loss_fn'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_to_save = {k: v for k, v in kwargs.items() if k != 'model'} #don't save NN as json\n",
    "kwargs_to_save['loss_fn'] = kwargs['loss_fn'].__name__ #replace function with a string\n",
    "if not isinstance(kwargs_to_save['epsilon'], float):\n",
    "    kwargs_to_save['epsilon'] = eps_list.tolist() #tensors aren't json compatible, use list\n",
    "with open(SAVE_DIR+f'{ATK_NAME} parameters.json', 'w') as f:\n",
    "    json.dump(kwargs_to_save, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CityLearnART",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
