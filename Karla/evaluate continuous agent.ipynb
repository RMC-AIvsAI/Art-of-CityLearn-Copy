{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_NAME = r\"Victims\\3-26-5_PPOc_citylearn_challenge_2022_phase_2_('Building_6',)_gSDE_norm_space_SolarPenaltyReward_deep_net_256_40000.zip\"\n",
    "DATASET_NAME = 'citylearn_challenge_2022_phase_2' #only action is electrical storage\n",
    "SAVE_DIR = '3-26-5 PPOc Karla results' + '/'\n",
    "#COL_NAME = '4-2-11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import SAC, PPO\n",
    "from citylearn.data import DataSet\n",
    "from citylearn.citylearn import CityLearnEnv, EvaluationCondition\n",
    "from citylearn.wrappers import StableBaselines3Wrapper, NormalizedSpaceWrapper\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_continuous_env(schema, bldg: list = None, single_agent: bool = True, seed:int = 0, T=None, env_kwargs:dict=dict()):\n",
    "    \"\"\"Because ART's attacks are designed for supervised learning they one work with ANNs with a single label or head, using multiple buildings adds an action/head for each\"\"\"\n",
    "    \n",
    "    #TODO support custom rewards\n",
    "    if bldg is None:\n",
    "        bldg = list(schema['buildings'].keys())[0] #the first building from the schema's building keys\n",
    "\n",
    "    kwargs = env_kwargs\n",
    "    \n",
    "    env = CityLearnEnv(schema, \n",
    "        central_agent=single_agent, \n",
    "        buildings=bldg, \n",
    "        random_seed=seed,\n",
    "        episode_time_steps=T,\n",
    "        **kwargs)\n",
    "    #Calendar observations are periodically normalized, everything else is min/max normalized \n",
    "    env = NormalizedSpaceWrapper(env)\n",
    "    #provides an interface for SB3\n",
    "    env = StableBaselines3Wrapper(env)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_kpis(env, eval_condition=None):\n",
    "    \"\"\"displays the KPIs from the evnironment's most recent timestep.\n",
    "    This function can be called after an agent runs in a test env to evaluate performance\"\"\"\n",
    "\n",
    "    if eval_condition is None:\n",
    "        eval_condition = EvaluationCondition.WITHOUT_STORAGE_BUT_WITH_PARTIAL_LOAD_AND_PV\n",
    "\n",
    "    kpis = env.evaluate(baseline_condition=eval_condition).pivot(index='cost_function', columns='name', values='value')\n",
    "    kpis = kpis.dropna(how='all')\n",
    "    kpis = kpis['District']\n",
    "    kpis = kpis[kpis != 0]\n",
    "    return kpis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_agent(env, agent):\n",
    "    \"\"\"evaluates the input agent for one episode\n",
    "    returns a df containing the KPIs, and arrays containing the observations and actions\"\"\"\n",
    "    obs_list = []\n",
    "    a_list = []\n",
    "\n",
    "    observations = env.reset()\n",
    "\n",
    "    while not env.done:\n",
    "        obs_list.append(observations)\n",
    "        actions, _ = agent.predict(observations, deterministic=True)\n",
    "        a_list.append(actions)\n",
    "        observations, _, _, _ = env.step(actions)\n",
    "    \n",
    "    return format_kpis(env), np.array(obs_list), np.array(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== CURRENT SYSTEM INFO ==\n",
      "- OS: Windows-10-10.0.22631-SP0 10.0.22631\n",
      "- Python: 3.10.12\n",
      "- Stable-Baselines3: 1.8.0\n",
      "- PyTorch: 1.12.1\n",
      "- GPU Enabled: True\n",
      "- Numpy: 1.25.1\n",
      "- Gym: 0.21.0\n",
      "\n",
      "== SAVED MODEL SYSTEM INFO ==\n",
      "- OS: Linux-5.15.0-78-generic-x86_64-with-glibc2.31 # 85~20.04.1-Ubuntu SMP Mon Jul 17 09:42:39 UTC 2023\n",
      "- Python: 3.10.13\n",
      "- Stable-Baselines3: 1.8.0\n",
      "- PyTorch: 1.12.1\n",
      "- GPU Enabled: False\n",
      "- Numpy: 1.25.1\n",
      "- Gym: 0.21.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent = PPO.load(path=f\"{AGENT_NAME}\",\n",
    "                 print_system_info=True,)\n",
    "\n",
    "schema = DataSet.get_schema(DATASET_NAME)\n",
    "env = make_continuous_env(schema=schema,  \n",
    "                                seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = env.observation_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([0.], [1.], (1,), float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticPolicy(\n",
       "  (features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (pi_features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (vf_features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=31, out_features=256, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=31, out_features=256, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (value_net): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'gae_lambda': agent.gae_lambda,\n",
    "    'batch_size': agent.batch_size,\n",
    "    #'clip_range': agent.clip_range, #function, not value\n",
    "    'clip_range_vf': agent.clip_range_vf,\n",
    "    'ent_coef': agent.ent_coef,\n",
    "    'gamma': agent.gamma,\n",
    "    'learning_rate': agent.learning_rate,\n",
    "    'n_epochs': agent.n_epochs,\n",
    "    'n_steps': agent.n_steps,\n",
    "    'target_kl': agent.target_kl,\n",
    "    'vf_coef': agent.vf_coef,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gae_lambda': 0.9639143359823201,\n",
       " 'batch_size': 64,\n",
       " 'clip_range_vf': None,\n",
       " 'ent_coef': 1.5635546620789673e-05,\n",
       " 'gamma': 0.9062274459056439,\n",
       " 'learning_rate': 8.377741144413337e-05,\n",
       " 'n_epochs': 8,\n",
       " 'n_steps': 512,\n",
       " 'target_kl': None,\n",
       " 'vf_coef': 0.5}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SAVE_DIR+f'agent hyperparameters.json', 'w') as f:\n",
    "    json.dump(hyperparams, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cost_function\n",
       "annual_peak_average                         1.000000\n",
       "carbon_emissions_total                      0.858946\n",
       "cost_total                                  0.813706\n",
       "daily_one_minus_load_factor_average      7869.833697\n",
       "daily_peak_average                          0.891421\n",
       "electricity_consumption_total               0.874358\n",
       "monthly_one_minus_load_factor_average       0.989392\n",
       "ramping_average                             0.942670\n",
       "zero_net_energy                             1.076963\n",
       "Name: District, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline_kpis, baseline_obs, baseline_a = eval_agent(env,agent)\n",
    "display(baseline_kpis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-26-5 PPOc Karla results/KPIs.csv created\n"
     ]
    }
   ],
   "source": [
    "kpi_savename = SAVE_DIR+'KPIs.csv'\n",
    "try:\n",
    "    df_kpis = pd.read_csv(kpi_savename,\n",
    "                          index_col=0)\n",
    "    df_kpis['baseline'] = baseline_kpis.values\n",
    "    df_kpis.to_csv(kpi_savename)\n",
    "    print(f'{kpi_savename} updated')\n",
    "except:\n",
    "    baseline_kpis.name = 'baseline'\n",
    "    baseline_kpis.to_csv(kpi_savename)\n",
    "    print(f'{kpi_savename} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sa = pd.DataFrame(baseline_obs)\n",
    "df_sa.columns = cols\n",
    "df_sa['actions'] = baseline_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sa.to_csv(SAVE_DIR+'baseline_obs-a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CityLearnART",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
