{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_NAME = '20 bin PPO 500 results\\default_PPO_citylearn_challenge_2022_phase_2_Building_6_20_bins_500.zip'\n",
    "DATASET_NAME = 'citylearn_challenge_2022_phase_2' #only action is electrical storage\n",
    "SAVE_DIR = r'20 bin PPO 500 results\\furthest action results' + '/'\n",
    "EPS = 0.10\n",
    "ATK_NAME = f'furthest action {EPS}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "from citylearn.data import DataSet\n",
    "\n",
    "from art.attacks.evasion import AutoConjugateGradient as ACG\n",
    "from art.utils import to_categorical\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import KBMproject.utilities as utils\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = DataSet.get_schema(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: #try to load CityLearn schema\n",
    "    schema = DataSet.get_schema(DATASET_NAME)\n",
    "except: #load saved schema otherwise\n",
    "    with open(DATASET_NAME, 'r') as file:\n",
    "        schema = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define RL agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== CURRENT SYSTEM INFO ==\n",
      "- OS: Windows-10-10.0.22631-SP0 10.0.22631\n",
      "- Python: 3.10.12\n",
      "- Stable-Baselines3: 1.8.0\n",
      "- PyTorch: 1.12.1\n",
      "- GPU Enabled: True\n",
      "- Numpy: 1.25.1\n",
      "- Gym: 0.21.0\n",
      "\n",
      "== SAVED MODEL SYSTEM INFO ==\n",
      "- OS: Windows-10-10.0.19045-SP0 10.0.19045\n",
      "- Python: 3.10.12\n",
      "- Stable-Baselines3: 1.8.0\n",
      "- PyTorch: 1.12.0\n",
      "- GPU Enabled: True\n",
      "- Numpy: 1.25.1\n",
      "- Gym: 0.21.0\n",
      "\n",
      "Model loaded from storage\n"
     ]
    }
   ],
   "source": [
    "agent = PPO.load(path=f\"{AGENT_NAME}\",\n",
    "                 print_system_info=True)\n",
    "print('Model loaded from storage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = agent.action_space[0].n\n",
    "env = utils.make_discrete_env(schema=schema,  \n",
    "                        action_bins=bins,\n",
    "                        seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = env.observation_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_masks = np.ones(agent.observation_space.shape)\n",
    "observation_masks[0:6] = 0 #mask time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.arange(agent.action_space[0].n))//2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define RL agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_furthest_action_attack(agent, env, ART_atk, time_steps:int=None, mask:list=None):\n",
    "    \"\"\"Evaluates an SB3 agent subject to untargeted observation perturbations generated by an ART evasion attack,\n",
    "    starting p[oints are added for the bb attack, which requires initialization from a sample of the target class\"\"\"\n",
    "\n",
    "    obs_list = []\n",
    "    adv_obs_list = []\n",
    "    adv_a_list = []\n",
    "    action_list = []\n",
    "    asr = tasr = 0\n",
    "    kwargs = dict()\n",
    "\n",
    "    action_space = np.arange(agent.action_space[0].n) #array of discrete actions, assumes 1d\n",
    "    action_mid = len(np.arange(agent.action_space[0].n))//2\n",
    "\n",
    "    observations = env.reset()\n",
    "    if time_steps is None:\n",
    "        time_steps = env.time_steps - 1\n",
    "    if mask is not None:\n",
    "        kwargs['mask'] = mask\n",
    "\n",
    "    pbar = tqdm(total=time_steps)\n",
    "    for step in range(time_steps):\n",
    "\n",
    "        obs_list.append(observations)\n",
    "        a, _ = agent.predict(observations, deterministic=True)\n",
    "        action_list.append(a)\n",
    "\n",
    "        #off by one error here,\n",
    "        if a[0] < action_mid: #try targets that flip the (dis)charge of the action\n",
    "            max = action_space[-1] #add 1?\n",
    "            min = action_space[action_mid]\n",
    "        else:\n",
    "            max = action_space[action_mid - 1]\n",
    "            min = action_space[0] #add 1?\n",
    "\n",
    "#instead of a binary search, a batch of idendical smaples paired with different targets could be computed\n",
    "    #then the batch is test on the victim and the successful sample chosen.\n",
    "            \n",
    "        kwargs['targeted'] = True\n",
    "        target = min\n",
    "        kwargs['y'] = to_categorical([target], nb_classes=agent.action_space[0].n) #one-hot encode int\n",
    "        adv_obs = np.squeeze(ART_atk.generate(np.expand_dims(observations, axis=0), **kwargs))\n",
    "        adv_a, _ = agent.predict(adv_obs, deterministic=True)\n",
    "\n",
    "        if target==adv_a[0]: #check if the action matches the intended target\n",
    "            asr+=1\n",
    "            tasr+=1\n",
    "            best_adv_obs = adv_obs\n",
    "            min += 1 #don't test this twice\n",
    "            while(max > min): #binary search for furthest action\n",
    "                target = min + (max - min)//2\n",
    "                kwargs['y'] = to_categorical([target], nb_classes=agent.action_space[0].n)\n",
    "                adv_obs = np.squeeze(ART_atk.generate(np.expand_dims(observations, axis=0), **kwargs))\n",
    "                adv_a, _ = agent.predict(adv_obs, deterministic=True)\n",
    "                if target==adv_a[0]: #check if the action matches the intended target\n",
    "                    best_adv_obs = adv_obs\n",
    "                    min = target\n",
    "                else:\n",
    "                    max = target\n",
    "            adv_obs_list.append(best_adv_obs)\n",
    "        else: #closest target failed\n",
    "            kwargs['targeted'] = False #use untargeted attack\n",
    "            kwargs['y'] = None\n",
    "            adv_obs = np.squeeze(ART_atk.generate(np.expand_dims(observations, axis=0), **kwargs))\n",
    "            adv_a, _ = agent.predict(adv_obs, deterministic=True)\n",
    "            if adv_a[0]!=a[0]: #check if untargeted attack succeeded\n",
    "                asr+=1\n",
    "                adv_obs_list.append(adv_obs)\n",
    "            else:\n",
    "                adv_obs_list.append(np.array([np.nan]*agent.observation_space.shape[0])) #same shape as observations\n",
    "            \n",
    "        \n",
    "        adv_a_list.append(adv_a)\n",
    "\n",
    "        observations, _, _, _ = env.step(adv_a)\n",
    "\n",
    "        #update progress bar including asr\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix({'ASR': asr/(step + 1),'Targeted ASR': tasr/(step + 1)}, refresh=True)\n",
    "        if env.done:\n",
    "            break\n",
    "    \n",
    "    pbar.close()\n",
    "    asr/=time_steps\n",
    "    return utils.format_kpis(env), np.array(obs_list), np.array(adv_obs_list), np.array(action_list), np.array(adv_a_list), asr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = 50\n",
    "iter = int(500/init)\n",
    "params = dict(\n",
    "    loss_type='difference_logits_ratio', \n",
    "    eps = EPS,\n",
    "    eps_step = 2*EPS,\n",
    "    batch_size=1,\n",
    "    nb_random_init=init, #5, lower values speed crafting\n",
    "    max_iter=iter, #iterations per restart\n",
    "    norm='inf', #->l2 ->l1 most restrictive \n",
    "    verbose=False,\n",
    ")\n",
    "attack = utils.define_attack(agent, ACG, ART_kwargs=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8759/8759 [11:05<00:00, 13.16it/s, ASR=0.997, Targeted ASR=0]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 50s\n",
      "Wall time: 11min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kpis, obs, adv_obs, actions, adv_actions, asr = eval_furthest_action_attack(agent, \n",
    "                                                                            env, \n",
    "                                                                            attack,\n",
    "                                                                            time_steps=None,\n",
    "                                                                            mask=observation_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For eps up to 0.1, the targeted attack never succeeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cost_function\n",
       "annual_peak_average                      1.289772\n",
       "carbon_emissions_total                   0.936198\n",
       "cost_total                               0.865539\n",
       "daily_one_minus_load_factor_average      1.119091\n",
       "daily_peak_average                       1.053599\n",
       "electricity_consumption_total            0.941203\n",
       "monthly_one_minus_load_factor_average    1.004105\n",
       "ramping_average                          1.444045\n",
       "zero_net_energy                          1.112498\n",
       "Name: District, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(kpis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi = kpis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 bin PPO 500 results\\furthest action results/KPIs.csv updated\n"
     ]
    }
   ],
   "source": [
    "kpi_savename = SAVE_DIR+'KPIs.csv'\n",
    "try:\n",
    "    df_kpis = pd.read_csv(kpi_savename, index_col=0)\n",
    "    df_kpis[ATK_NAME] = kpi.values\n",
    "    df_kpis.to_csv(kpi_savename)\n",
    "    print(f'{kpi_savename} updated')\n",
    "except:\n",
    "    kpi.name = ATK_NAME\n",
    "    kpi.to_csv(kpi_savename)\n",
    "    print(f'{kpi_savename} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obs = pd.DataFrame(obs)\n",
    "df_obs.columns = cols\n",
    "df_obs['a'] = actions\n",
    "df_obs.to_csv(SAVE_DIR+ATK_NAME+'a-obs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obs = pd.DataFrame(adv_obs)\n",
    "df_obs.columns = cols\n",
    "df_obs['a'] = adv_actions\n",
    "df_obs.to_csv(SAVE_DIR+ATK_NAME+' adv a-obs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 bin PPO 500 results\\furthest action results/ASRs.csv updated\n"
     ]
    }
   ],
   "source": [
    "asr_savename = SAVE_DIR+'ASRs.csv'\n",
    "try:\n",
    "    df_asrs = pd.read_csv(asr_savename)\n",
    "    df_asrs[ATK_NAME] = asr\n",
    "    df_asrs.to_csv(asr_savename)\n",
    "    print(f'{asr_savename} updated')\n",
    "except:\n",
    "    asr = pd.Series([asr])\n",
    "    asr.name = ATK_NAME\n",
    "    asr.to_csv(asr_savename)\n",
    "    print(f'{asr_savename} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CityLearnART",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
