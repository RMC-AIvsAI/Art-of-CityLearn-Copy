{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_NAME = '20 bin PPO 500 results/default_PPO_citylearn_challenge_2022_phase_2_Building_6_20_bins_500.zip'\n",
    "ATTACK = 'myBB'\n",
    "TRIAL_PATH ='optuna/bb hyperparameters 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "from citylearn.data import DataSet\n",
    "\n",
    "from KBMproject.mybb import BrendelBethgeAttack as BBA\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import KBMproject.utilities as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define RL agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from storage\n"
     ]
    }
   ],
   "source": [
    "agent = PPO.load(path=f\"{AGENT_NAME}\")\n",
    "print('Model loaded from storage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.estimators.classification import PyTorchClassifier as classifier\n",
    "from torch.nn import CrossEntropyLoss\n",
    "victim_policy = classifier(\n",
    "    model=utils.extract_actor(agent),\n",
    "    loss=CrossEntropyLoss(), \n",
    "    nb_classes=agent.action_space[0].n,\n",
    "    input_shape=agent.observation_space.shape,\n",
    "    device_type='gpu',\n",
    "    clip_values = (agent.observation_space.low.min(),agent.observation_space.high.max()) #min and max values of each feature, brendle bethge attack only supports floats values and not array\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_time = np.ones(agent.observation_space.shape)\n",
    "mask_time[:6] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline = pd.concat([pd.read_csv('20 bin PPO 500 results/baseline_obs.csv', index_col=0,dtype='float32'),\n",
    "                        pd.read_csv('20 bin PPO 500 results/baseline_obs_a_confidence.csv', index_col=0)], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, for each action we select the sample with the highest logit softmax/confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max_confidence_samples = df_baseline.loc[df_baseline.groupby('action')['confidence'].idxmax()]\n",
    "df_max_confidence_samples = df_max_confidence_samples.drop(columns='confidence')\n",
    "df_max_confidence_samples = df_max_confidence_samples.set_index('action')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_samples = df_max_confidence_samples.T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_csv('20 bin PPO 500 results/bb results/optimal myBB observations.csv', index_col=0,dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save clean obs from optimal bb attack in trial folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = samples.to_numpy()[:-1]\n",
    "np.savetxt(f\"{TRIAL_PATH}/inputs.csv\", inputs, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate advserarial actions and save in trial folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.argmax(victim_policy.predict(pd.read_csv('20 bin PPO 500 results/bb results/optimal myBB adversarial observations.csv',\n",
    "                                            index_col=0,\n",
    "                                            dtype='float32')\n",
    "                                            ), axis=1)\n",
    "np.savetxt(f\"{TRIAL_PATH}/targets.csv\", targets, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate advsersarial initiializations and save in trial folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = np.array([np.array(list(\n",
    "    dict_samples[a].values())).astype('float32') if a in dict_samples else np.zeros(agent.observation_space.shape, 'float32') for a in targets]) \n",
    "#there is no example for action 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f\"{TRIAL_PATH}/starts.csv\", starts, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save victim policy in trial folder\n",
    "\n",
    "There's no way to laod it as an ART classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "measure how long one trial would take/how long it takes to generate adv samples for an episode:\n",
    "\n",
    "should be about 20 minutes, but that' only with one running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CityLearnART",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
